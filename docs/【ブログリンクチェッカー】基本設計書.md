## ブログ記事リンクチェッカー自動化プロジェクト 基本設計書

### 1. 概要
本ドキュメントは、「ブログ記事リンクチェッカー自動化プロジェクト 要件定義書」に基づき、システムの実現方式を定義する基本設計書です。本設計書は、後続の工程である詳細設計および実装のインプットとなることを目的とします。

### 2. システム構成

#### 2.1. システム構成図
**【ブログリンクチェッカー】システム構成図.drawio**を参照

#### 2.2. 利用技術・サービス
| 分類 | 技術・サービス名 | 目的 |
| :--- | :--- | :--- |
| **クラウド** | Amazon Web Services (AWS) | インフラ基盤 |
| **IaC** | Terraform | AWSリソースのコードによる管理 |
| **コンピューティング** | AWS Lambda | リンクチェック処理の実行 |
| **ストレージ** | Amazon S3 | チェック対象URLリストの配置、結果レポートの保存 |
| **モニタリング** | Amazon CloudWatch | ログ監視、アラーム通知 |
| **通知** | Amazon SNS | エラー発生時の管理者への通知 |
| **開発言語** | Python | Lambda関数の実装 |
| **外部サービス** | Google Apps Script | Googleスプレッドシートからのデータ取得とS3へのアップロード |

#### 2.3. 実行環境・ライブラリ

| コンポーネント | 設定項目 | 設定値（例） | 備考 |
| :--- | :--- | :--- | :--- |
| **AWS Lambda** | ランタイム | Python 3.13 | |
| | Pythonライブラリ | requests, BeautifulSoup4, boto3 | |
| **Google Apps Script** | 実行環境 | V8ランタイム　| |
| | ライブラリ | サードパーティ製のライブラリ（S3） | |
| | サービス | Google Sheets API | |

### 3. 機能設計

#### 3.1. データ準備機能 (GAS: 事前処理)
*   **処理概要:** 定時トリガーで起動し、チェック対象のURLリストをS3にアップロードする。
*   **入力:**
    *   原本スプレッドシート
    *   作業用スプレッドシート
*   **処理シーケンス:**
    1.  定時トリガー（日次）により起動。
    2.  作業用スプレッドシートの既存データをクリアする。
    3.  原本スプレッドシートから最新のチェック対象URLリストを作業用スプレッドシートにコピーする。
    4.  自動取得したURLと手動登録しているURLリスト件数の合計を確認して、URLリスト件数用のシートに記載されている前回件数と比較する。
    5.  件数が異なる場合、管理者宛に`MailApp`で件数変動通知メールを送信する。
    6.  現在のURLリスト件数をURLリスト件数用のシートに保存する。
    7.  自動取得・手動登録のURLリスト情報を、JSON形式のデータファイルとして作成する。
    8.  対象のS3バケットにデータファイルをアップロードする。
*   **出力:**
    *   S3へのデータファイルアップロード
    *   (変動時) 管理者への通知メール
*   **エラー処理:** スプレッドシートへのアクセス失敗、S3へのアップロード失敗時は、エラー内容をログに出力し、`MailApp`で管理者にエラー通知を送信して処理を中断する。

#### 3.2. リンクチェック機能 (AWS Lambda: メイン処理)
*   **処理概要:** S3へのファイルアップロードをトリガーに、指定されたブログURLをクロールして広告リンクを抽出し、リンク切れをチェックして結果をCSV形式でS3に出力する。
*   **入力:**
    *   S3イベント (バケット名、オブジェクトキー)
    *   S3上のJSONファイル。`auto_url_list`と`manual_url_list`の2つのキーを持つ。
*   **処理シーケンス:**
    1.  S3へのファイルPUTをトリガーに起動。
    2.  `boto3`を使用し、トリガーとなったS3バケットから入力JSONファイルを読み込む。
    3.  JSONデータをパースし、`auto_url_list`（自動クロール対象）と`manual_url_list`（手動チェック対象）を取得する。
    4.  **自動URLリスト (`auto_url_list`) の処理:**
        a. リスト内の各ブログURL（はてなブログ、ライブドアブログ）に対してループ実行。
        b. **クロール処理:**
            - **はてなブログ:** `rel='next'` を持つ `<a>` タグを辿り、ブログの全ページをクロールする。
            - **ライブドアブログ:** `a.next` や "次へ" といったセレクタで次ページを検索し、全一覧ページをクロール。各一覧ページから個別記事のURLを抽出する。
        c. **広告リンク抽出:**
            - 各ページ（はてな）または各記事ページ（ライブドア）のHTMLコンテンツを取得する。
            - 「※一部、広告・宣伝が含まれます。」という文字列を検索する。
            - 上記文字列の直後にある最初の `<a>` タグの `href` を広告リンクとして抽出する。
        d. 抽出した広告リンクが `EXCLUDE_STRINGS`（環境変数）を含まないかチェックする。
        e. 広告リンクが見つからない場合は、その旨を結果に記録する。
    5.  **手動URLリスト (`manual_url_list`) の処理:**
        a. リスト内の各アイテムから `affiliate_link` を取得する。
        b. リンクが `EXCLUDE_STRINGS` を含まないかチェックする。
    6.  **リンクステータスチェック (自動・手動共通):**
        a. 抽出された各リンクに対し、`ThreadPoolExecutor` を使用して並列でチェックを実行する。
        b. `requests.get` を使用してHTTP GETリクエストを送信する（リトライ: 環境変数 `MAX_RETRIES` 回、タイムアウト: 環境変数 `REQUEST_TIMEOUT` 秒）。
        c. JavaScriptによるリダイレクトを考慮し、`meta http-equiv="refresh"` タグを最大5回まで追跡する。
        d. レスポンスのHTMLコンテンツに `NG_WORDS`（環境変数）が含まれていないか確認する。
        e. 400番未満のステータスコードで、かつNGワードやその他特定ドメイン（jass-net.com等）の条件に合致しない場合を「OK」と判断する。それ以外は「NG」として記録する。
    7.  全てのチェック結果をCSV形式にまとめる。
    8.  `boto3`を使用し、S3バケットに結果ファイル `linkcheck_result.csv` をアップロードする。
*   **出力:**
    *   S3へのCSVファイル (`linkcheck_result.csv`) アップロード
*   **エラー処理:**
    *   **リトライ可能エラー:** HTTPリクエスト失敗時（ステータスコード 429, 5xx系）、設定された回数リトライを実行する。
    *   **致命的エラー:** S3からのファイル読み込み失敗、JSONパース失敗、必須環境変数の欠如など、処理続行不可能なエラーが発生した場合、エラー情報をCloudWatch Logsに出力して処理を中断する。

#### 3.3. 結果反映・差分比較・報告機能 (GAS: 事後処理)
*   **処理概要:** 定時トリガーで起動し、S3から結果ファイルを取得してスプレッドシートに反映。前回結果との差分を検出し、管理者に報告する。
*   **入力:**
    *   S3バケット内の結果ファイル
    *   作業用スプレッドシート (ID: `yyyyyyyy`)
*   **処理シーケンス:**
    1.  定時トリガー（毎日 AM 6:00 JSTなど、メイン処理の完了を見越した時間）により起動。
    2.  S3バケットの`output/`フォルダ内をリストし、最新の結果ファイル（`result_...json`）を取得・読み込む。
    3.  結果ファイル内のタイムスタンプが当日でない場合、処理異常とみなし、管理者にエラー通知を送信して処理を終了する。
    4.  作業用スプレッドシートの「当日シート」の内容を「前日シート」に全上書きコピーする。
    5.  読み込んだ最新のチェック結果で「当日シート」をクリア＆ライトする。
    6.  「当日シート」と「前日シート」のデータをキー（元記事URL＋リンクURL）で比較し、差分（新規エラー、修正済み、削除）を検出する。
    7.  差分があったセルに対し、以下の書式設定を適用する。
        *   **新規エラー:** セルの背景色を赤にする。
        *   **修正済み:** 文字に取消線を引く。
        *   **削除されたリンク:** 行全体の背景色を灰色にする。
    8.  差分の有無に応じてメールを作成し、`MailApp`で管理者に完了報告メールを送信する。差分がある場合は、その内容をメール本文に記載する。
    9.  現在の「当日シート」を`YYYY-MM-DD_backup`という名前で複製し、履歴として保管する。
    10. 30日以上経過したバックアップシートを検索し、削除する。
*   **出力:**
    *   更新された作業用スプレッドシート
    *   管理者への完了報告メール
*   **エラー処理:** S3からの結果ファイル取得失敗、JSONパース失敗、スプレッドシートへの書き込み失敗時は、エラー内容をログに出力し、管理者にエラー通知を送信して処理を中断する。

### 4. データ設計

#### 4.1. Googleスプレッドシート設計
*   **原本スプレッドシート**
    *   シート名: `URLリスト`
    *   カラム定義:
        | カラム名 | データ型 | 説明 |
        | :--- | :--- | :--- |
        | `記事URL` | 文字列 | チェック対象のブログ記事URL |
        | `プラットフォーム`| 文字列 | `はてなブログ` or `ライブドアブログ` |
        | `手動追加リンク` | 文字列 | 自動抽出に加え、個別でチェックしたいリンクURL（任意） |

*   **作業用スプレッドシート**
    *   シート構成: `当日シート`, `前日シート`, `YYYY-MM-DD_backup` (複数)
    *   カラム定義 (各シート共通):
        | カラム名 | データ型 | 説明 |
        | :--- | :--- | :--- |
        | `記事URL` | 文字列 | リンクが掲載されている元記事のURL |
        | `リンク先URL` | 文字列 | チェック対象のハイパーリンクURL |
        | `アンカーテキスト` | 文字列 | リンクに設定されているテキスト |
        | `ステータスコード` | 数値/文字列 | HTTPレスポンスのステータスコード (例: 200, 404, 'TIMEOUT') |
        | `結果` | 文字列 | `OK` or `NG` |
        | `最終チェック日時`| 日時文字列 | Lambdaがチェックを実行した日時 (YYYY-MM-DD HH:MI:SS) |

#### 4.2. S3連携ファイル設計
*   **GAS -> Lambda (input/....json)**
    *   フォーマット: JSON
    *   内容: `auto_url_list` と `manual_url_list` の2つのキーを持つJSONオブジェクト。
    *   例:
    ```json
    {
      "auto_url_list": [
        {
          "url": "https://example-hatena.hatenablog.com/"
        },
        {
          "url": "https://example-livedoor.livedoor.blog/"
        }
      ],
      "manual_url_list": [
        {
          "spreadsheet_link": "https://manual-check.com/page1",
          "blog_article_url": "https://manual-check.com/page1",
          "affiliate_link": "https://affiliate.example.com/link1"
        }
      ]
    }
    ```

*   **Lambda -> GAS (output/linkcheck_result.csv)**
    *   フォーマット: CSV
    *   内容: 広告リンクのチェック結果リスト。
    *   ヘッダー: `スプレッドシート記載のリンク`, `ブログ記事URL`, `アフィリエイト広告リンク`, `確認結果`, `ステータスコード`, `アフィリエイト広告リンク先URL`, `エラーメッセージ`, `タイムスタンプ`
    *   例:
    ```csv
    スプレッドシート記載のリンク,ブログ記事URL,アフィリエイト広告リンク,確認結果,ステータスコード,アフィリエイト広告リンク先URL,エラーメッセージ,タイムスタンプ
    https://example-hatena.hatenablog.com/,https://example-hatena.hatenablog.com/entry/2025/09/19/123456,https://ad-service.com/ad1,OK,200,https://ad-service.com/ad1,,2025-09-19T10:00:00+09:00
    https://example-hatena.hatenablog.com/,https://example-hatena.hatenablog.com/entry/2025/09/18/000000,https://ad-service.com/ad2,NG,404,https://ad-service.com/ad2,"HTTPError('404 Client Error: Not Found for url: https://ad-service.com/ad2')",2025-09-19T10:00:01+09:00
    https://manual-check.com/page1,https://manual-check.com/page1,https://affiliate.example.com/link1,NG,,https://affiliate.example.com/link1,"Meta refresh redirect limit exceeded",2025-09-19T10:00:02+09:00
    ```

### 5. 非機能要件設計

| 項目 | 設計内容 |
| :--- | :--- |
| **セキュリティ** | 1. GASのスクリプトプロパティに、AWSのアクセスキー/シークレットキーを直接保存せず、OAuth2などの認証フローを検討するか、IAMロールとサービスアカウントを利用したよりセキュアな認証方式を採用する。 2. LambdaにアタッチするIAMロールのポリシーは、対象のS3バケットとSNSトピックに限定したアクション（`s3:GetObject`, `s3:PutObject`, `sns:Publish`）のみを許可する。 |
| **保守性・運用** | 1. S3バケット名、スプレッドシートID、通知先メールアドレス、バックアップ保持日数などの設定値は、GASはスクリプトプロパティ、Lambdaは環境変数で管理し、コードと分離する。 2. LambdaのログはAmazon CloudWatch LogsにJSON形式で出力し、エラーレベル（ERROR, WARN, INFO）を明確にする。 3. GASのログはGoogle Cloud Loggingで確認可能とする。 |